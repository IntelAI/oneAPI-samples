{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Samples to Get Started with Intel® oneAPI  AI Analytics Toolkit\n",
    "\n",
    "This AI Kit JupyterHub platform also features several samples to get started with understanding how some Intel® oneAPI AI Analytics Toolkit delivers optimized and scalable solutions for deep learning and machine learning data science workflows. \n",
    "\n",
    "Below are the list of samples included for RHODS users:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Intel Optimized_TensorFlow_and_INC_Quantization_Tool_E2E_Sample**: This sample utilizes Intel-optimized Tensorflow and INC (Intel® Neural Compressor) in the Intel® oneAPI AI Analytics Toolkit offered in the RHODS platform. The sample will train MNIST with Intel-optimized Tensorflow on alexnet, followed by quantizing with INC to convert fp32 trained model to int8 low-precision model and perform optimized inference. This sample will also provide performance and accuracy comparisons on fp32 vs int8 inference highlighting the importance of using LPOT in Intel® oneAPI AI Analytics Toolkit to  perform low-precision inference. **Open the [inc_sample_tensorflow.ipynb](./Intel_Optimized_TensorFlow_and_INC_Quantization_Tool_E2E_Sample/inc_sample_tensorflow.ipynb) notebook and follow the instructions to run.**\n",
    "\n",
    "2.  **Intel_Modin_and_Intel_Extension_for_Scikit-Learn_E2E_Sample**: This sample will introduce users how to use Intel® Distribution of Modin and Intel® Extension for Scikit-Learn from the Intel® oneAPI API analytics toolkit offered in the RHODS platform.  The sample trains US Census data with Intel® Extension for Scikit-Learn and utilizes Intel® Distribution of Modin on Pandas to perform optimized and distributed data preprocessing calls such as read_csv and other ETL operations.  **Open the [census_modin.ipynb](./Intel_Modin_and_Intel_Extension_for_Scikit-Learn_E2E_Sample/census_modin.ipynb) notebook and follow the instructions to run.**\n",
    "\n",
    "3. **Intel_Extension_for_PyTorch_GettingStarted_and_AutoMixedPrecision_Sample**: This sample code shows how to get started with Intel Extension for PyTorch as well as how to use AutoMixedPrecision with Intel Extension for PyTorch to extend the official PyTorch with optimizations for extra performance boost on Intel hardware.  **Open the [Intel_Extension_for_PyTorch_GettingStarted_and_AutoMixedPrecision.ipynb](./Intel_Extension_for_PyTorch_GettingStarted_and_AutoMixedPrecision_Sample/Intel_Extension_for_PyTorch_Getting_Started_and_AutoMixedPrecision.ipynb) notebook and follow the instructions to run.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Intel Model Zoo is also shipped as part of the toolkit and can be found in the \"models\" folder. Go to `/models.git/quickstart` to learn more on how to run various models offered as part of Intel Model Zoo.\n",
    "\n",
    "**For even more samples,** please visit the [Intel® oneAPI  AI Analytics Toolkit](https://github.com/oneapi-src/oneAPI-samples/tree/master/AI-and-Analytics) repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
